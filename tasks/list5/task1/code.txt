library(maxLik)

# 1. Definiujemy funkcję Log-Likelihood
# Zwracamy samą wartość, ale Gradient i Hessian podamy osobno
logLik_Fun <- function(beta) {
  # Beta to nasz parametr do znalezienia (jedna liczba)
  Phi <- pnorm(beta)      # Dystrybuanta
  
  # Log-likelihood: 5 sukcesów, 3 porażki
  ll <- 5 * log(Phi) + 3 * log(1 - Phi)
  return(ll)
}

# 2. Definiujemy Gradient (Wektor pierwszych pochodnych)
grad_Fun <- function(beta) {
  phi <- dnorm(beta)      # Gęstość
  Phi <- pnorm(beta)      # Dystrybuanta
  
  # Wzór wyprowadzony wyżej
  g <- phi * (5/Phi - 3/(1 - Phi))
  return(g)
}

# 3. Definiujemy Hessian (Macierz drugich pochodnych)
hess_Fun <- function(beta) {
  phi <- dnorm(beta)
  Phi <- pnorm(beta)
  
  # Pomocnicze zmienne (Inverse Mills Ratios)
  lambda1 <- phi / Phi
  lambda0 <- phi / (1 - Phi)
  
  # Wzór na drugą pochodną dla Probitu
  # Część od sukcesów (5) i porażek (3)
  h <- -5 * lambda1 * (lambda1 + beta) - 3 * lambda0 * (lambda0 - beta)
  
  # Hessian musi być macierzą (tutaj 1x1)
  return(as.matrix(h)) 
}

# 4. Uruchomienie optymalizacji
# Podajemy funkcję, gradient i hessian.
# Startujemy np. od 0 (co oznacza p=0.5)
wynik <- maxLik(logLik = logLik_Fun, 
                grad = grad_Fun, 
                hess = hess_Fun, 
                start = c(0))

# 5. Wyniki
summary(wynik)

# --- WERYFIKACJA WYNIKÓW ---
cat("------------------------------------------------\n")
beta_hat <- coef(wynik)
p_hat <- pnorm(beta_hat)

cat("Oszacowane Beta:", beta_hat, "\n")
cat("Oszacowane P (powinno być 5/8 = 0.625):", p_hat, "\n")
cat("Sprawdzenie analityczne 5/8:", 5/8, "\n")