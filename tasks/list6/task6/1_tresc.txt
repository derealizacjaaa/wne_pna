<h2>Zadanie 6: Regresja liniowa z MLE - vacation.csv</h2>

<p>Wykorzystując dane z pliku <code>vacation.csv</code> dla modelu regresji liniowej:</p>

<p><strong>MILES<sub>i</sub> = β₀ + β₁ · INCOME<sub>i</sub> + ε</strong>, gdzie ε ~ N(0, σ²)</p>

<h3>Zadania - Podejście Maximum Likelihood:</h3>
<ol>
  <li>Ręcznie zdefiniować funkcję log-wiarygodności</li>
  <li>Wyprowadzić i zaimplementować gradient (wektor pierwszych pochodnych)</li>
  <li>Wyprowadzić i zaimplementować hesjan (macierz drugich pochodnych)</li>
  <li>Użyć pakietu <code>maxLik</code> do estymacji parametrów</li>
  <li>Zwizualizować ścieżkę optymalizacji od punktu startowego</li>
</ol>

<h3>Model teoretyczny:</h3>
<p>Dla regresji liniowej zakładamy, że błędy mają rozkład normalny:</p>
<p>y<sub>i</sub> ~ N(β₀ + β₁x<sub>i</sub>, σ²)</p>

<p>Funkcja wiarygodności dla n obserwacji:</p>
<p>L(β₀, β₁, σ²) = ∏ (1/√(2πσ²)) · exp(-(y<sub>i</sub> - β₀ - β₁x<sub>i</sub>)² / (2σ²))</p>

<p>Log-wiarygodność:</p>
<p>ℓ(β₀, β₁, σ²) = -n/2 · ln(2π) - n/2 · ln(σ²) - 1/(2σ²) · ∑(y<sub>i</sub> - β₀ - β₁x<sub>i</sub>)²</p>

<p><strong>Uwaga:</strong> Estymatory MLE dla β₀ i β₁ są identyczne z metodą najmniejszych kwadratów (OLS)!</p>
